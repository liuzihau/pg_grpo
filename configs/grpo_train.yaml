# Stage 3: GRPO on top of your KD LoRA
data:
  source: hf
  hf_name: allenai/tulu-3-sft-mixture
  messages_field: messages
  keep_history: true
  split: grpo
  max_input_len: 4096
  load_kwargs: {}
  sample_max: null

grpo:
  # model related
  base_model_dir: outputs/kd/qwen3_draft_lora      # path containing kd cfg + adapters (or adapters in ./lora)
  out_dir: outputs/grpo/qwen3_grpo
  
  # data related
  use_pregen_prompts: true
  pregen_dir: data/kd_corpus/qwen8b_S64_topk20
  pregen_split: grpo              # or validation
  offset_strategy: uniform        # "uniform" | "stride"
  offset_stride: 8               # 0, 8, 16, ... up to cont_len-1
  cushion: 8                  # reserved tokens (guard room)

  valid_every: 200              # run validation every N steps
  valid_use_pregen_prompts: true   # default = same as train if omitted
  valid_pregen_split: validation   # pregen split for val
  valid_hf_split: validation       # HF split for val (when not using pregen)
  valid_sample_max: 512            # cap #validation prompts (null = all)
  valid_batch_size: 1              # keep tiny; we force group_size=1 anyway
  valid_temperature: null          # null => use training temperature
  valid_acceptance_cap: null       # null => use training cap


  # train related
  reward_key: accepted_tokens
  batch_size: 1
  group_size: 8               # GRPO: samples per prompt
  total_steps: 10000
  lr: 5.0e-5
  weight_decay: 0.0
  betas: [0.9, 0.95]
  warmup_ratio: 0.05
  min_lr: 0.0
  max_new: 8 #128
  temperature: 0.8
  acceptance_cap: 1.0
  grad_accum_steps: 2
  log_every: 1
  teacher_device: cpu         # "auto" (default GPU) or "cpu" to fully offload teacher
  teacher_8bit: false         # set true if you have bitsandbytes and want GPU 8-bit teacher
  teacher_microbatch: 8
  teacher_device: "auto"      # or "cpu"
  teacher_8bit: false
  # regularization
  kl_ref: draft_init          # teacher | draft_init | none
  kl_ref_update_every: 1000   # <-- H steps; 0 disables refresh

  kl_coeff: 0.1
  print_layers: true

training:
  seed: 1234
  device: cuda
  dtype: bf16
  grad_ckpt: true
  max_grad_norm: 1.0

logging:
  project: grpo-qwen
  name: qwen3_grpo_from_kd
