# Stage 3: GRPO on top of your KD LoRA
data:
  source: hf
  hf_name: allenai/tulu-3-sft-mixture
  messages_field: messages
  keep_history: true
  split: train
  max_input_len: 4096
  load_kwargs: {}
  sample_max: null

grpo:
  base_model_dir: outputs/kd/qwen3_draft_lora      # path containing kd cfg + adapters (or adapters in ./lora)
  out_dir: outputs/grpo/qwen3_grpo
  batch_size: 8
  group_size: 4               # GRPO: samples per prompt
  total_steps: 2000
  lr: 5.0e-5
  weight_decay: 0.0
  betas: [0.9, 0.95]
  warmup_ratio: 0.05
  min_lr: 0.0
  max_new: 128
  temperature: 0.8
  acceptance_cap: 1.0
  grad_accum_steps: 1
  log_every: 20
  teacher_device: cpu         # "auto" (default GPU) or "cpu" to fully offload teacher
  teacher_8bit: false         # set true if you have bitsandbytes and want GPU 8-bit teacher
  group_size: 4               # reduce if still tight on memory
  batch_size: 2               # reduce if still tight on memory
  max_new: 64                 # reduce max_new to trim sequence length


  # regularization
  kl_ref: teacher             # teacher | draft_init | none
  kl_coeff: 0.01

  print_layers: true

training:
  seed: 1234
  device: cuda
  dtype: bf16
  max_grad_norm: 1.0

logging:
  project: grpo-qwen
  name: qwen3_grpo_from_kd
