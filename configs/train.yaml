models:
  tokenizer: Qwen/Qwen3-0.6B
  target:    Qwen/Qwen3-8B
  draft:     Qwen/Qwen3-0.6B

data:
  source: hf
  hf_name: allenai/tulu-3-sft-mixture
  split: train
  messages_field: messages
  sample_max: 50000
  keep_history: true
  max_input_len: 1024

kd_pregen:
  out_dir: data/kd_corpus/qwen8b_S64_temp0   # where to store shards + teacher_head.pt
  num_samples: 10000                         # 4kâ€“20k as you said
  shard_size: 2000                           # items per .pt
  S: 64                                      # continuation length to generate
  split: train                               # which split to draw prompts from
  seed: 1234

  # generation settings (defaults fall back to kd.* if omitted)
  temperature: 0.0
  top_p: 1.0
  top_k: 0

lora:
  target_modules: ["q_proj","k_proj","v_proj","o_proj","up_proj","down_proj","gate_proj"]
  r: 32
  alpha: 32
  dropout: 0.05
  task_type: "CAUSAL_LM"

training:
  project: specdec-two-stage
  device: cuda
  dtype: bf16
  seed: 1234
  lr: 1.0e-4
  weight_decay: 0.01
  max_grad_norm: 1.0
  group_size: 4
  ppo_clip_eps: 0.2
  S: 2
  batch_prompts: 2
  temperature: 0.8
  save_every: 2000
  output_dir: outputs

kd:
  use_pregen: true
  pregen_dir: data/kd_corpus/qwen8b_S64_temp0
  lr: 5.0e-4
  weight_decay: 0.0
  warmup_ratio: 0.05
  margin_gamma: 0.5
  margin_center: 1.0
  w_min: 0.2
  mismatch_lambda: 0.3
  total_steps: 4000
  batch_size: 4
  log_every: 1
  temperature: 0.0
  curriculum:
    max_input_len_start: 512
    max_input_len_end: 2048
    max_new_tokens_start: 128
    max_new_tokens_end: 512

grpo:
  total_steps: 30000

reward:
  divergence: kl
  alpha: 0.5
  topk_for_ce: 0
  entropy_bonus: 0.003
  anchor_kl_beta: 0.03
  clip_reward: true
  clip_range: [-20.0, 0.0]
  advantage_norm: std

eval:
  enabled: true
  n_prompts: 64          # how many prompts to eval
  gen_tokens: 128        # continuation length for eval
  every_steps_kd: 200    # evaluate every K KD steps
  every_steps_grpo: 1000 # evaluate every K GRPO steps
  split: validation      # for HF datasets; fallbacks provided
  temperature: 0.0       # greedy eval
  prompts_path: null     # (optional) local path for eval prompts if not using HF

logging:
  project: specdec-two-stage
  name: qwen0p6_to_8b_lora_two_stage

